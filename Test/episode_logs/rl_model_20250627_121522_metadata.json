{
    "episode_name": "rl_model_20250627_121522",
    "controller_type": "rl_model",
    "model_path": "../Environment/results/ppo_20250623_134204/logs/models/ppo_final_model.zip",
    "vec_normalize_path": "../Environment/results/ppo_20250623_134204/logs/models/vec_normalize.pkl",
    "used_normalization": true,
    "hysteresis": null,
    "total_steps": 2880,
    "total_reward": 2969.167431064183,
    "avg_reward_per_step": 1.0309609135639524,
    "episode_length_hours": 24.0,
    "timestamp": "2025-06-27T12:15:24.955208",
    "env_config": {
        "episode_length": 2880,
        "time_step_seconds": 30,
        "initial_heating_setpoint": 26.0,
        "initial_cooling_setpoint": 28.0,
        "external_temp_pattern": "sine",
        "setpoint_pattern": "schedule",
        "reward_type": "balanced",
        "energy_weight": 0.5,
        "comfort_weight": 1.0,
        "random_start_time": true,
        "use_reward_shaping": true
    },
    "performance": {
        "avg_ground_temp": 21.69476890563965,
        "avg_top_temp": 22.194522857666016,
        "avg_external_temp": 19.985254287719727,
        "total_comfort_violations": 449.35585542292125,
        "total_energy_use": 298.0,
        "comfort_violation_rate": 0.2520833333333333,
        "avg_lights_on": 0.10347222222222222,
        "avg_windows_open": 0.8840277777777777
    }
}